{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from alpha_vantage.timeseries import TimeSeries \n",
    "\n",
    "print(\"All libraries loaded\")\n",
    "\n",
    "config = {\n",
    "    \"alpha_vantage\": {\n",
    "        \"key\": \"demo\", # you can use the demo API key for this project, but please make sure to get your own API key at https://www.alphavantage.co/support/#api-key\n",
    "        \"symbol\": \"IBM\",\n",
    "        \"outputsize\": \"full\",\n",
    "        \"key_adjusted_close\": \"5. adjusted close\",\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"window_size\": 20,\n",
    "        \"train_split_size\": 0.80,\n",
    "    }, \n",
    "    \"plots\": {\n",
    "        \"xticks_interval\": 90, # show a date every 90 days\n",
    "        \"color_actual\": \"#001f3f\",\n",
    "        \"color_train\": \"#3D9970\",\n",
    "        \"color_val\": \"#0074D9\",\n",
    "        \"color_pred_train\": \"#3D9970\",\n",
    "        \"color_pred_val\": \"#0074D9\",\n",
    "        \"color_pred_test\": \"#FF4136\",\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"input_size\": 1, # since we are only using 1 feature, close price\n",
    "        \"num_lstm_layers\": 2,\n",
    "        \"lstm_size\": 32,\n",
    "        \"dropout\": 0.2,\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"device\": \"cpu\", # \"cuda\" or \"cpu\"\n",
    "        \"batch_size\": 64,\n",
    "        \"num_epoch\": 100,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"scheduler_step_size\": 40,\n",
    "    }\n",
    "}\n",
    "def download_data(config):\n",
    "    ts = TimeSeries(key='demo') #you can use the demo API key for this project, but please make sure to eventually get your own API key at https://www.alphavantage.co/support/#api-key. \n",
    "    data, meta_data = ts.get_daily_adjusted(config[\"alpha_vantage\"][\"symbol\"], outputsize=config[\"alpha_vantage\"][\"outputsize\"])\n",
    "\n",
    "    data_date = [date for date in data.keys()]\n",
    "    data_date.reverse()\n",
    "\n",
    "    data_close_price = [float(data[date][config[\"alpha_vantage\"][\"key_adjusted_close\"]]) for date in data.keys()]\n",
    "    data_close_price.reverse()\n",
    "    data_close_price = np.array(data_close_price)\n",
    "\n",
    "    num_data_points = len(data_date)\n",
    "    display_date_range = \"from \" + data_date[0] + \" to \" + data_date[num_data_points-1]\n",
    "    print(\"Number data points\", num_data_points, display_date_range)\n",
    "\n",
    "    return data_date, data_close_price, num_data_points, display_date_range\n",
    "\n",
    "data_date, data_close_price, num_data_points, display_date_range = download_data(config)\n",
    "\n",
    "# plot\n",
    "\n",
    "fig = figure(figsize=(25, 5), dpi=80)\n",
    "fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
    "plt.plot(data_date, data_close_price, color=config[\"plots\"][\"color_actual\"])\n",
    "xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i==num_data_points-1) else None for i in range(num_data_points)] # make x ticks nice\n",
    "x = np.arange(0,len(xticks))\n",
    "plt.xticks(x, xticks, rotation='vertical')\n",
    "plt.title(\"Daily close price for \" + config[\"alpha_vantage\"][\"symbol\"] + \", \" + display_date_range)\n",
    "plt.grid(visible=None, which='major', axis='y', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "class Normalizer():\n",
    "    def __init__(self):\n",
    "        self.mu = None\n",
    "        self.sd = None\n",
    "\n",
    "    def fit_transform(self, x):\n",
    "        self.mu = np.mean(x, axis=(0), keepdims=True)\n",
    "        self.sd = np.std(x, axis=(0), keepdims=True)\n",
    "        normalized_x = (x - self.mu)/self.sd\n",
    "        return normalized_x\n",
    "\n",
    "    def inverse_transform(self, x):\n",
    "        return (x*self.sd) + self.mu\n",
    "\n",
    "# normalize\n",
    "scaler = Normalizer()\n",
    "normalized_data_close_price = scaler.fit_transform(data_close_price)\n",
    "def prepare_data_x(x, window_size):\n",
    "    # perform windowing\n",
    "    n_row = x.shape[0] - window_size + 1\n",
    "    output = np.lib.stride_tricks.as_strided(x, shape=(n_row, window_size), strides=(x.strides[0], x.strides[0]))\n",
    "    return output[:-1], output[-1]\n",
    "\n",
    "\n",
    "def prepare_data_y(x, window_size):\n",
    "    # # perform simple moving average\n",
    "    # output = np.convolve(x, np.ones(window_size), 'valid') / window_size\n",
    "\n",
    "    # use the next day as label\n",
    "    output = x[window_size:]\n",
    "    return output\n",
    "\n",
    "data_x, data_x_unseen = prepare_data_x(normalized_data_close_price, window_size=config[\"data\"][\"window_size\"])\n",
    "data_y = prepare_data_y(normalized_data_close_price, window_size=config[\"data\"][\"window_size\"])\n",
    "\n",
    "# split dataset\n",
    "\n",
    "split_index = int(data_y.shape[0]*config[\"data\"][\"train_split_size\"])\n",
    "data_x_train = data_x[:split_index]\n",
    "data_x_val = data_x[split_index:]\n",
    "data_y_train = data_y[:split_index]\n",
    "data_y_val = data_y[split_index:]\n",
    "\n",
    "# prepare data for plotting\n",
    "\n",
    "to_plot_data_y_train = np.zeros(num_data_points)\n",
    "to_plot_data_y_val = np.zeros(num_data_points)\n",
    "\n",
    "to_plot_data_y_train[config[\"data\"][\"window_size\"]:split_index+config[\"data\"][\"window_size\"]] = scaler.inverse_transform(data_y_train)\n",
    "to_plot_data_y_val[split_index+config[\"data\"][\"window_size\"]:] = scaler.inverse_transform(data_y_val)\n",
    "\n",
    "to_plot_data_y_train = np.where(to_plot_data_y_train == 0, None, to_plot_data_y_train)\n",
    "to_plot_data_y_val = np.where(to_plot_data_y_val == 0, None, to_plot_data_y_val)\n",
    "\n",
    "## plots\n",
    "\n",
    "fig = figure(figsize=(25, 5), dpi=80)\n",
    "fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
    "plt.plot(data_date, to_plot_data_y_train, label=\"Prices (train)\", color=config[\"plots\"][\"color_train\"])\n",
    "plt.plot(data_date, to_plot_data_y_val, label=\"Prices (validation)\", color=config[\"plots\"][\"color_val\"])\n",
    "xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i==num_data_points-1) else None for i in range(num_data_points)] # make x ticks nice\n",
    "x = np.arange(0,len(xticks))\n",
    "plt.xticks(x, xticks, rotation='vertical')\n",
    "plt.title(\"Daily close prices for \" + config[\"alpha_vantage\"][\"symbol\"] + \" - showing training and validation data\")\n",
    "plt.grid(visible=None, which='major', axis='y', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        x = np.expand_dims(x, 2) # in our case, we have only 1 feature, so we need to convert `x` into [batch, sequence, features] for LSTM\n",
    "        self.x = x.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx], self.y[idx])\n",
    "\n",
    "dataset_train = TimeSeriesDataset(data_x_train, data_y_train)\n",
    "dataset_val = TimeSeriesDataset(data_x_val, data_y_val)\n",
    "\n",
    "print(\"Train data shape\", dataset_train.x.shape, dataset_train.y.shape)\n",
    "print(\"Validation data shape\", dataset_val.x.shape, dataset_val.y.shape)\n",
    "\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=32, num_layers=2, output_size=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.linear_1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(hidden_layer_size, hidden_size=self.hidden_layer_size, num_layers=num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(num_layers*hidden_layer_size, output_size)\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                 nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                 nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                 nn.init.orthogonal_(param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "\n",
    "        # layer 1\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # LSTM layer\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        # reshape output from hidden cell into [batch, features] for `linear_2`\n",
    "        x = h_n.permute(1, 0, 2).reshape(batchsize, -1) \n",
    "        \n",
    "        # layer 2\n",
    "        x = self.dropout(x)\n",
    "        predictions = self.linear_2(x)\n",
    "        return predictions[:,-1]\n",
    "    pass\n",
    "def run_epoch(dataloader, is_training=False):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    if is_training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    for idx, (x, y) in enumerate(dataloader):\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        batchsize = x.shape[0]\n",
    "\n",
    "        x = x.to(config[\"training\"][\"device\"])\n",
    "        y = y.to(config[\"training\"][\"device\"])\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out.contiguous(), y.contiguous())\n",
    "\n",
    "        if is_training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss += (loss.detach().item() / batchsize)\n",
    "\n",
    "    lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    return epoch_loss, lr\n",
    "\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
    "\n",
    "model = LSTMModel(input_size=config[\"model\"][\"input_size\"], hidden_layer_size=config[\"model\"][\"lstm_size\"], num_layers=config[\"model\"][\"num_lstm_layers\"], output_size=1, dropout=config[\"model\"][\"dropout\"])\n",
    "model = model.to(config[\"training\"][\"device\"])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"training\"][\"learning_rate\"], betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config[\"training\"][\"scheduler_step_size\"], gamma=0.1)\n",
    "\n",
    "for epoch in range(config[\"training\"][\"num_epoch\"]):\n",
    "    loss_train, lr_train = run_epoch(train_dataloader, is_training=True)\n",
    "    loss_val, lr_val = run_epoch(val_dataloader)\n",
    "    scheduler.step()\n",
    "    \n",
    "    print('Epoch[{}/{}] | loss train:{:.6f}, test:{:.6f} | lr:{:.6f}'\n",
    "              .format(epoch+1, config[\"training\"][\"num_epoch\"], loss_train, loss_val, lr_train))\n",
    "    pass\n",
    "# here we re-initialize dataloader so the data doesn't shuffled, so we can plot the values by date\n",
    "\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=config[\"training\"][\"batch_size\"], shuffle=False)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=config[\"training\"][\"batch_size\"], shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# predict on the training data, to see how well the model managed to learn and memorize\n",
    "\n",
    "predicted_train = np.array([])\n",
    "\n",
    "for idx, (x, y) in enumerate(train_dataloader):\n",
    "    x = x.to(config[\"training\"][\"device\"])\n",
    "    out = model(x)\n",
    "    out = out.cpu().detach().numpy()\n",
    "    predicted_train = np.concatenate((predicted_train, out))\n",
    "\n",
    "# predict on the validation data, to see how the model does\n",
    "\n",
    "predicted_val = np.array([])\n",
    "\n",
    "for idx, (x, y) in enumerate(val_dataloader):\n",
    "    x = x.to(config[\"training\"][\"device\"])\n",
    "    out = model(x)\n",
    "    out = out.cpu().detach().numpy()\n",
    "    predicted_val = np.concatenate((predicted_val, out))\n",
    "\n",
    "# prepare data for plotting\n",
    "\n",
    "to_plot_data_y_train_pred = np.zeros(num_data_points)\n",
    "to_plot_data_y_val_pred = np.zeros(num_data_points)\n",
    "\n",
    "to_plot_data_y_train_pred[config[\"data\"][\"window_size\"]:split_index+config[\"data\"][\"window_size\"]] = scaler.inverse_transform(predicted_train)\n",
    "to_plot_data_y_val_pred[split_index+config[\"data\"][\"window_size\"]:] = scaler.inverse_transform(predicted_val)\n",
    "\n",
    "to_plot_data_y_train_pred = np.where(to_plot_data_y_train_pred == 0, None, to_plot_data_y_train_pred)\n",
    "to_plot_data_y_val_pred = np.where(to_plot_data_y_val_pred == 0, None, to_plot_data_y_val_pred)\n",
    "\n",
    "# plots\n",
    "\n",
    "fig = figure(figsize=(25, 5), dpi=80)\n",
    "fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
    "plt.plot(data_date, data_close_price, label=\"Actual prices\", color=config[\"plots\"][\"color_actual\"])\n",
    "plt.plot(data_date, to_plot_data_y_train_pred, label=\"Predicted prices (train)\", color=config[\"plots\"][\"color_pred_train\"])\n",
    "plt.plot(data_date, to_plot_data_y_val_pred, label=\"Predicted prices (validation)\", color=config[\"plots\"][\"color_pred_val\"])\n",
    "plt.title(\"Compare predicted prices to actual prices\")\n",
    "xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i==num_data_points-1) else None for i in range(num_data_points)] # make x ticks nice\n",
    "x = np.arange(0,len(xticks))\n",
    "plt.xticks(x, xticks, rotation='vertical')\n",
    "plt.grid(visible=None, which='major', axis='y', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# prepare data for plotting the zoomed in view of the predicted prices (on validation set) vs. actual prices\n",
    "\n",
    "to_plot_data_y_val_subset = scaler.inverse_transform(data_y_val)\n",
    "to_plot_predicted_val = scaler.inverse_transform(predicted_val)\n",
    "to_plot_data_date = data_date[split_index+config[\"data\"][\"window_size\"]:]\n",
    "\n",
    "# plots\n",
    "\n",
    "fig = figure(figsize=(25, 5), dpi=80)\n",
    "fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
    "plt.plot(to_plot_data_date, to_plot_data_y_val_subset, label=\"Actual prices\", color=config[\"plots\"][\"color_actual\"])\n",
    "plt.plot(to_plot_data_date, to_plot_predicted_val, label=\"Predicted prices (validation)\", color=config[\"plots\"][\"color_pred_val\"])\n",
    "plt.title(\"Zoom in to examine predicted price on validation data portion\")\n",
    "xticks = [to_plot_data_date[i] if ((i%int(config[\"plots\"][\"xticks_interval\"]/5)==0 and (len(to_plot_data_date)-i) > config[\"plots\"][\"xticks_interval\"]/6) or i==len(to_plot_data_date)-1) else None for i in range(len(to_plot_data_date))] # make x ticks nice\n",
    "xs = np.arange(0,len(xticks))\n",
    "plt.xticks(xs, xticks, rotation='vertical')\n",
    "plt.grid(visible=None, which='major', axis='y', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# predict the closing price of the next trading day\n",
    "\n",
    "model.eval()\n",
    "\n",
    "x = torch.tensor(data_x_unseen).float().to(config[\"training\"][\"device\"]).unsqueeze(0).unsqueeze(2) # this is the data type and shape required, [batch, sequence, feature]\n",
    "prediction = model(x)\n",
    "prediction = prediction.cpu().detach().numpy()\n",
    "\n",
    "# prepare plots\n",
    "\n",
    "plot_range = 10\n",
    "to_plot_data_y_val = np.zeros(plot_range)\n",
    "to_plot_data_y_val_pred = np.zeros(plot_range)\n",
    "to_plot_data_y_test_pred = np.zeros(plot_range)\n",
    "\n",
    "to_plot_data_y_val[:plot_range-1] = scaler.inverse_transform(data_y_val)[-plot_range+1:]\n",
    "to_plot_data_y_val_pred[:plot_range-1] = scaler.inverse_transform(predicted_val)[-plot_range+1:]\n",
    "\n",
    "to_plot_data_y_test_pred[plot_range-1] = scaler.inverse_transform(prediction)\n",
    "\n",
    "to_plot_data_y_val = np.where(to_plot_data_y_val == 0, None, to_plot_data_y_val)\n",
    "to_plot_data_y_val_pred = np.where(to_plot_data_y_val_pred == 0, None, to_plot_data_y_val_pred)\n",
    "to_plot_data_y_test_pred = np.where(to_plot_data_y_test_pred == 0, None, to_plot_data_y_test_pred)\n",
    "\n",
    "# plot\n",
    "\n",
    "plot_date_test = data_date[-plot_range+1:]\n",
    "plot_date_test.append(\"tomorrow\")\n",
    "\n",
    "fig = figure(figsize=(25, 5), dpi=80)\n",
    "fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
    "plt.plot(plot_date_test, to_plot_data_y_val, label=\"Actual prices\", marker=\".\", markersize=10, color=config[\"plots\"][\"color_actual\"])\n",
    "plt.plot(plot_date_test, to_plot_data_y_val_pred, label=\"Past predicted prices\", marker=\".\", markersize=10, color=config[\"plots\"][\"color_pred_val\"])\n",
    "plt.plot(plot_date_test, to_plot_data_y_test_pred, label=\"Predicted price for next day\", marker=\".\", markersize=20, color=config[\"plots\"][\"color_pred_test\"])\n",
    "plt.title(\"Predicted close price of the next trading day\")\n",
    "plt.grid(visible=None, which='major', axis='y', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Predicted close price of the next trading day:\", round(to_plot_data_y_test_pred[plot_range-1], 2))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
